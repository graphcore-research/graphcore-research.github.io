---
title: "April Papers: Motion Prompting, Mamba Reasoning and Modeling Rewards"
header:
    teaser: /assets/images/posts/2025-04/potm/twitter_card.png
    image: /assets/images/posts/2025-04/potm/twitter_card.png
    og_image: /assets/images/posts/2025-04/potm/twitter_card.png

date: 2025-05-07T01:00:00-00:00
potm_year: 2025
potm_month: 4

layout: paper-summaries-layout
category: "papers-of-the-month"
toc: true
toc_sticky: true
toc_label: "Papers"
toc_icon: "book"
author.twitter: "GCResearchTeam"
---

April has been a busy month for the AI research community, with ICLR (the first of the "big three" AI conferences of the year)
being held towards the end of the month. We're pleased to share summaries of a few of our favourite papers we've seen this month.

First up, [Motion Prompting](#motion-prompting-controlling-video-generation-with-motion-trajectories) introduces flexible spatio-temporal trajectories, or "motion prompts", as a powerful new way to
control nuanced dynamic actions and motion in video generation, overcoming the limitations of text prompts.
This is followed by [Inference-Time Scaling for Generalist Reward Modeling](#inference-time-scaling-for-generalist-reward-modeling), which presents Self-Principled Critique Tuning (SPCT),
a method that powers DeepSeek-GRMâ€”a generalist reward model capable of generating adaptive, high-quality rewards and achieving
strong performance gains through scalable inference-time compute.
Finally, [M1](#m1-towards-scalable-test-time-compute-with-mamba-reasoning-models) looks at using a Mambda-based architecture to tackle reasoning problems, as a more computationally-efficient approach
when compared to transformers with chains-of-thought.


*We hope you enjoy this month's papers as much as we did! If you have thoughts or questions, please reach out to us at [@GCResearchTeam](https://x.com/GCResearchTeam).*

---

{% include paper-summaries.md %}