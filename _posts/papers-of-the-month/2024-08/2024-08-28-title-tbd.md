---
title: "August Papers: Hallucination, Quantisation and Test-Time Computation"
header:
    teaser: /assets/images/posts/2024-07/potm/twitter_card.png
    image: /assets/images/posts/2024-07/potm/twitter_card.png
    og_image: /assets/images/posts/2024-07/potm/twitter_card.png

date: 2024-08-28T01:00:00-00:00
potm_year: 2024
potm_month: 8

layout: paper-summaries-layout
category: "papers-of-the-month"
toc: true
toc_sticky: true
toc_label: "Papers"
toc_icon: "book"
author.twitter: "GCResearchTeam"
---

This month,  from August look

The first paper we cover investigates two methods for allowing LLMs to improve task performance on challenging prompts by expending more test-time compute. Further, they propose a scaling strategy to allocate test-time compute on a per-prompt basis, and show that thoughtful increases in the test-time compute budget for a small model can be more effective than training larger models.

Our second chosen paper constructs a training dataset where correct answers can always be known, enabling accurate measurement of hallucinations in LLMs. This facilitates an analysis of hallucincation rates and hallucaination detectability as training compute is scaled. 

Finally, the third paper describes _Spectra_, an open suite of 54 LLMs and 500+ intermediate checkpoints from 0.1B to 3.9B, spanning FP16 trianing, ternary training, and post-training quantisation to 3, 4, 6, and 8 bits. The proposed ternary architecture - TriLM - outperforms BitNet b1.58 models of similar size.

_I hope you enjoy these as much as we did. If you have thoughts or questions, keep the conversation going [@GCResearchTeam](https://x.com/GCResearchTeam)._

---

{% include paper-summaries.md %}
