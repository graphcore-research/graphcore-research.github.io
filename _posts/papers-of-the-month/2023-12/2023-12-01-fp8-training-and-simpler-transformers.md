---
title: "December Papers: FP8 Training & Simpler Transformers"
header.teaser: /assets/images/posts/2023-12/potm/chipnemo/fig1.png

date: 2023-12-01T01:34:30-04:00
potm_year: 2023
potm_month: 12

layout: paper-summaries-layout
category: "papers-of-the-month"
toc: true
toc_label: "Papers"
toc_icon: "book"
---

The last month saw impressive developments in the space of efficient transformers
and applied ML, from materials discovery to chip design.

Researchers at Microsoft showed that FP8 could be used in parts of the LLM training
process that until now had been kept in higher-precision, and work from ETH Zurich
suggested a simplified way of designing transformer-like models.

In terms of applications, DeepMind have impressive results showing that GNNs can be used
in the discovery of new inorganic crystals â€” a key building block of many modern
technologies. Nvidia have also trained up an impressive model to assist their
engineers on chip design. This is a neat feedback loop: their chip-design has been
making LLMs better for years, and now their LLMs are making chip-design better.

{% include paper-summaries.md %}
