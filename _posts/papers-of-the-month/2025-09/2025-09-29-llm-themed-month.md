---
title: "September Papers: The L in ML Stands for LLMs"
header:
    teaser: /assets/images/posts/2025-09/potm/twitter_card.png
    image: /assets/images/posts/2025-09/potm/twitter_card.png
    og_image: /assets/images/posts/2025-09/potm/twitter_card.png

date: 2025-10-07T01:00:00-00:00
potm_year: 2025
potm_month: 9

layout: paper-summaries-layout
category: "papers-of-the-month"
toc: true
toc_sticky: true
toc_label: "Papers"
toc_icon: "book"
author.twitter: "GCResearchTeam"
---

For September, the research team reviewed a whopping 22 papers! Needless to say, competition was fierce, and only four made the final cut for this month’s edition, which is LLM-themed:  

- [FlowRL](#flowrl-matching-reward-distributions-for-llm-reasoning) uses GFlowNets to train LLMs on full reward distributions, promoting diverse reasoning paths instead of just reward maximization.  
- [Soft Tokens, Hard Truths](#soft-tokens-hard-truths) proposes using continuous “soft” tokens with injected noise to enable reinforcement learning fine-tuning of LLM reasoning.  
- [Set Block Decoding](#set-block-decoding-is-a-language-model-inference-accelerator) accelerates LLM inference by generating multiple tokens in parallel using non-causal attention and iterative entropy-based sampling.  
- [Metacognitive Reuse](#metacognitive-reuse-turning-recurring-llm-reasoning-into-concise-behaviors) enables LLMs to extract and reuse concise reasoning “behaviors” to improve efficiency and reduce repeated computation.  

*We hope you enjoy this month’s papers as much as we did! If you have thoughts or questions, please reach out to us at [@GCResearchTeam](https://x.com/GCResearchTeam).*  

---

{% include paper-summaries.md %}
