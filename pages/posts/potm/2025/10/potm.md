---
date: 2025-11-04
categories:
- Papers of the Month
title: 'October Papers: Fast and Smart Language Models'
merge_potm: true
---

October was packed with insights into making language models faster and smarter. We reviewed four of our favorite papers for you in detail:

- First up, [Grouped Lattice Vector Quantisation](#learning-grouped-lattice-vector-quantizers-for-low-bit-llm-compression) introduces a novel technique for a fine-grained post-training quantisation of LLMs, retaining good performance even at low bit widths.
- [Planned Diffusion](#planned-diffusion) combines autoregressive planning with text diffusion, achieving low-latency text generation.
- [Rethinking Thinking](#rethinking-thinking-tokens-llms-as-improvement-operators) addresses the problem of long reasoning chains by distilling intermediate results into a bounded workspace for faster answers.
- Finally, [When Structure Doesnâ€™t Help](#when-structure-doesnt-help-llms-do-not-read-text-attributed-graphs-as-effectively-as-we-expected) compares techniques for encoding graphs for consumption by LLMs with surprising results.
