---
date: 2025-12-08
categories:
- Papers of the Month
title: 'November Papers: Perspectives on efficiency'
merge_potm: true
---

November is back to a favourite topic of ours: efficiency. We reviewed three of our favorite papers looking on LLM efficiency from different angles:

- First up, [How to Scale Second-Order Optimization](#how-to-scale-second-order-optimization) is looking at optimal tuning of second order optimizers such as Muon. 
- [Intelligence per Watt](#intelligence-per-watt-measuring-intelligence-efficiency-of-local-ai) discusses our favorite metric on large language models: energy efficiency. And how to take advantage of edge AI inference.
- Finally, [Int vs FP](#int-vs-fp-a-comprehensive-study-of-fine-grained-low-bit-quantization-formats) is contributing to an old-timer topic in quantization: integer vs floating (block) point formats.
