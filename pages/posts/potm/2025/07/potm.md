---
date: 2025-08-01
categories:
- Papers of the Month
title: 'July Papers: Subliminal Learning, Mixture of Recursions and Dataset Curation'
merge_potm: true
---

As July brought tennis at Wimbledon, so too did the ML world serve up a volley of research. This month, we took an eagle-eyed approach—or, perhaps, *Hawk Eye*d approach—to three papers.

In our first paper, [Subliminal Learning](#subliminal-learning-language-models-transmit-behavioral-traits-via-hidden-signals-in-data) addresses the question, "Can we control or filter the distillation training data so that a student learns desirable properties but avoids picking up undesirable traits?" The authors conclude that the student learns *all* the teacher's traits, whether they're desirable or not!

Next, [Mixture of Recursions](#mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation) brings a twist to token-level computation: instead of fixed-depth processing, the model learns to recurse adaptively, allocating compute per token dynamically and efficiently—like a rally whose length depends on the importance of the point.

Last up is [DataRater](#datarater-meta-learned-dataset-curation), where the problem of dataset quality is addressed. A 'rater' is meta-learned to curate training data without manual filtering—an ace for data-centric AI.
