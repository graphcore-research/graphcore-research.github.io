---
date: 2025-07-01
categories:
- Papers of the Month
title: 'June Papers: Gradient Norms, LLM Reasoning and Video Generation'
merge_potm: true
---

This June not only brought us very hot and sunny days (at least here in the UK), but also an excellent selection of new and exciting ML research! Out of the many good candidates, this month we selected three papers, covering quite a lot of different ground.

In the first paper, [Why Gradients Rapidly Increase Near the End of Training](#why-gradients-rapidly-increase-near-the-end-of-training), a researcher from FAIR explores the puzzling phenomenon of increasing gradient magnitudes during training, offering an elegant mathematical explanation and a simple remedy.

Next, in [ProRL](#prorl-prolonged-reinforcement-learning-expands-reasoning-boundaries-in-large-language-models), NVIDIA researchers dive into the evolving topic of large language model reasoning, showing how prolonged reinforcement learning can indeed introduce novel reasoning abilities.

Finally, we look at [AAPT](#autoregressive-adversarial-post-training-for-real-time-interactive-video-generation), a fresh approach from the ByteDance Seed team that turns pre-trained offline diffusion models into real-time video generators via adversarial post-training.
